{"componentChunkName":"component---src-templates-blog-post-js","path":"/stable-difussion-cheat-sheet/","result":{"data":{"site":{"siteMetadata":{"title":"Boris D. Teoharov's Blog"}},"markdownRemark":{"id":"3f682840-abea-543d-a6cb-3fa9711c5bcb","excerpt":"This cheat sheet provides a detailed overview of key parameters and techniques for troubleshooting and optimizing Stable Diffusion, a powerful image generationâ€¦","html":"<p>This cheat sheet provides a detailed overview of key parameters and techniques for troubleshooting and optimizing Stable Diffusion, a powerful image generation model. By understanding and adjusting settings such as clip skip, CFG, preprocessing resolution, input image cropping, and samplers, users can achieve the desired balance between generation speed, image quality, and prompt adherence.</p>\n<h2>Clip Skip</h2>\n<ul>\n<li>Higher values (e.g., 2-3): Faster generation, lower quality, less prompt adherence</li>\n<li>Lower values (e.g., 1): Slower generation, higher quality, better prompt adherence</li>\n<li>Troubleshooting:</li>\n<li>High clip skip + high resolution = blurry, low-quality results</li>\n<li>Low clip skip + low resolution = overworked, inconsistent results</li>\n<li>Optimization:</li>\n<li>Adjust clip skip based on desired balance between speed and quality</li>\n<li>Decrease clip skip when increasing preprocessing resolution</li>\n</ul>\n<h2>CFG (Classifier Free Guidance)</h2>\n<ul>\n<li>Higher values (e.g., 10-15): Stronger prompt adherence, potential artifacts</li>\n<li>Lower values (e.g., 5-7): More creative interpretation, less prompt adherence</li>\n<li>Troubleshooting:</li>\n<li>High CFG + low steps = artifacts, overemphasis on prompt</li>\n<li>Low CFG + high steps = slow generation, lack of prompt adherence</li>\n<li>Optimization:</li>\n<li>Adjust CFG based on desired balance between prompt adherence and creativity</li>\n<li>Decrease CFG if hitting step count limits to manage computational demands</li>\n</ul>\n<h2>Preprocessing Resolution</h2>\n<ul>\n<li>Higher resolution: More detail, slower processing, requires lower clip skip</li>\n<li>Lower resolution: Less detail, faster processing, allows higher clip skip</li>\n<li>Troubleshooting:</li>\n<li>High resolution + high clip skip = artifacts, mutations</li>\n<li>Low resolution + low clip skip = overprocessed, inconsistent results</li>\n<li>Optimization:</li>\n<li>Match preprocessing resolution to target image resolution</li>\n<li>Adjust clip skip accordingly to maintain quality and efficiency</li>\n</ul>\n<h2>Input Image Cropping</h2>\n<ul>\n<li>Tighter cropping: Enhances focus on main subject, reduces processing steps</li>\n<li>Looser cropping: Maintains context and composition, requires more processing</li>\n<li>Troubleshooting:</li>\n<li>Over-cropping = loss of context, unnatural appearance</li>\n<li>Under-cropping = wasted processing on irrelevant areas</li>\n<li>Optimization:</li>\n<li>Crop tightly around main subject while preserving essential context</li>\n<li>Test different cropping levels to find the optimal balance</li>\n</ul>\n<h2>Samplers</h2>\n<ul>\n<li>Euler a: Non-ancestral Euler method, faster but less accurate</li>\n<li>Euler: Ancestral Euler method, balanced speed and quality</li>\n<li>DPM++ 2M Karras: Efficient sampler with Karras noise schedule, good for general use</li>\n<li>DPM++ SDE Karras: Stochastic differential equation (SDE) sampler with Karras noise schedule</li>\n<li>...</li>\n</ul>\n<p>Troubleshooting:</p>\n<ul>\n<li>Lack of diversity = try DPM++ SDE or UniPC samplers</li>\n<li>Oversaturation or artifacts = try Euler or DPM++ 2M Karras samplers</li>\n<li>Slow generation = try Euler a or DPM++ 2M samplers</li>\n</ul>\n<p>Optimization:</p>\n<ul>\n<li>Use Euler a or DPM++ 2M for fast iterations and drafts</li>\n<li>Use DPM++ 2M Karras or DPM++ SDE for balanced speed and quality</li>\n<li>Use DPM++ 3M SDE or UniPC for high-quality, diverse results</li>\n<li>Experiment with different noise schedules (e.g., Karras, exponential) to fine-tune results</li>\n</ul>\n<h2>General Optimization Tips</h2>\n<ul>\n<li>Experiment with different settings to find the best combination for your use case</li>\n<li>Keep detailed records of settings and results for future reference</li>\n<li>Seek feedback from others to validate improvements and gain new insights</li>\n<li>Balance generation speed and image quality based on your priorities</li>\n<li>Use preprocessing and postprocessing techniques to enhance input and output images</li>\n<li>Stay updated with the latest techniques and advancements in the field</li>\n<li>Share your findings and contribute to the community for mutual learning and growth</li>\n</ul>","frontmatter":{"title":"Stable Diffusion Cheat Sheet: Troubleshooting and Optimization","date":"May 04, 2023","description":"A comprehensive guide to optimizing Stable Diffusion settings for high-quality, efficient image generation."}},"previous":{"fields":{"slug":"/about/"},"frontmatter":{"title":"About Boris D. Teoharov"}},"next":{"fields":{"slug":"/pushing-the-stable-diffussion-limits/"},"frontmatter":{"title":"Pushing the Limits: Generating High-Quality, Photorealistic Images with Stable Diffusion"}}},"pageContext":{"id":"3f682840-abea-543d-a6cb-3fa9711c5bcb","previousPostId":"b3859e89-663f-55df-b5f9-8dda00a4a70b","nextPostId":"1314d85e-b6bb-5943-9851-6e7860f14d06"}},"staticQueryHashes":["2841359383","3257411868"],"slicesMap":{}}